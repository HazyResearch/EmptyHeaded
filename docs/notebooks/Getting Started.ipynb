{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figs/eh_logo.png\" style=\"width: 200px;\">\n",
    "\n",
    "# Getting started with EmptyHeaded\n",
    "\n",
    "This tutorial provides the basic information to get you up and running with EmptyHeaded. In this tutorial we show you how to make databases great again:\n",
    "\n",
    "1. Provide a brief [system overview](#system_overview) \n",
    "2. Show how to [run a sample query](#run_a_query)\n",
    "\n",
    "This example assumes that you have resolved all dependencies listed on our [GitHub](https://github.com/hazyresearch/EmptyHeaded) page and were able to  successfully setup the EmptyHeaded environment and compile the engine.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before we go any further, make sure you have done the following **prior** to loading this notebook:\n",
    "\n",
    "1. Run *source ./env.sh* in the root of the EmptyHeaded repository.\n",
    "2. Run *./compile.sh* in the root of the EmptyHeaded repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='system_overview'></a>\n",
    "\n",
    "# System Overview\n",
    "\n",
    "The EmptyHeaded engine works in three phases:\n",
    "(1) the query compiler translates a high-level datalog-like query\n",
    "language into a logical query plan represented as a\n",
    "GHD, replacing relational algebra in its traditional role; (2) the query compiler\n",
    "generates code for the execution engine by translating the GHD into a\n",
    "series of set intersections and loops; and (3) the execution engine\n",
    "performs automatic algorithmic and representation decisions based upon\n",
    "skew in the data.\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align:left\">\n",
    "<img src=\"../figs/systemOverview.png\" style=\"width: 550px\">\n",
    "</div>\n",
    "\n",
    "1. **Query Compiler**: our query compiler is written in Scala and the code can be found [here](https://github.com/HazyResearch/EmptyHeaded/tree/master/query_compiler).\n",
    "2. **Code Generation**: our code generator is written in Scala and the code can be found [here](https://github.com/HazyResearch/EmptyHeaded/tree/master/query_compiler).\n",
    "3. **Storage Engine**: our storage engine is written in C++ and the code can be found [here](https://github.com/HazyResearch/EmptyHeaded/tree/master/storage_engine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_a_query'></a>\n",
    "\n",
    "# Run a Query\n",
    "\n",
    "We now show how to run a query in the EmptyHeaded engine. There are 3 phases to running a query in the EmptyHeaded engine:\n",
    "\n",
    "1. [Build a database](#build_db)\n",
    "2. [Execute a query](#execute)\n",
    "3. [Inspect output data.](#inspect)\n",
    "\n",
    "We overview each phase next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build_db'></a>\n",
    "## Build a database\n",
    "\n",
    "The easiest way to get data in and out of the EmptyHeaded engine is via Pandas DataFrames. Note: we currently only accept DataFrames that contain numeric types but we show in our [rdf tutorial](https://github.com/HazyResearch/EmptyHeaded/tree/master/docs/notebooks/rdf) how one can bypass using Pandas and load data directly into the EmptyHeaded engine (for things like strings).\n",
    "\n",
    "The process of building a EmptyHeaded database is the process of loading tables, dictionary encoding these tables, and translating these tables into Tries which are our core data structure. We then write these tries to disk in a binary format which can be loaded as needed for query exection. A visual description of this process is below. \n",
    "\n",
    "<br/>\n",
    "<img src=\"../figs/table_transform.png\" style=\"width: 550px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, enough talking, let's start running! First import the emptyheaded python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from emptyheaded import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our query compiler is written in Scala. We spin up the JVM with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change how many threads we run with, etc., via the configuration that will be used for the database instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(system: emptyheaded, num_threads: 4,\n",
      "\t\tnum_sockets: 4, layout: hybrid, memory: RAM)\n"
     ]
    }
   ],
   "source": [
    "c = Config(num_threads=4)\n",
    "print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pandas DataFrames\n",
    "\n",
    "We accept data in the form of a Pandas DataFrame. Lets [read some data from a csv file](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) into a Pandas DataFrame. This dataset is a (small) graph dataset from our [Snap](https://snap.stanford.edu/data/egonets-Facebook.html) friends. \n",
    "\n",
    "The accepted datatypes when transferring Pandas DataFrames into the EmptyHeaded engine are:\n",
    "\n",
    "- np.int32,\n",
    "- np.int64,\n",
    "- np.uint32,\n",
    "- np.uint64,\n",
    "- np.float32,\n",
    "- np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eh = os.path.expandvars(\"$EMPTYHEADED_HOME\")\n",
    "df_graph = pd.read_csv(eh+'/test/graph/data/facebook_duplicated.tsv',\\\n",
    "  sep='\\t',\\\n",
    "  names=[\"0\",\"1\"],\\\n",
    "  dtype={\"0\":np.uint32,\"1\":np.uint32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's create a relation. A relation has a name and takes a dataframe that contains the data. The schema is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge = Relation(\n",
    "  name=\"Edge\",\n",
    "  dataframe=df_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are finally ready to create a database. The database accepts a config (we created one above), a path to the folder where the database will be placed on disk (must not exist already), and a list of relations that the database will contain. This step is slow in comparison to the others as it compiles the backend for the config requirements specified, performs dictionary encoding, builds tries, and writes tries to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "java.lang.ExceptionPyRaisable",
     "evalue": "java.lang.Exception: ERROR DATABASE FOLDER EXISTS OR IS AN INVALID PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mjava.lang.ExceptionPyRaisable\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d895be64c991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0meh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/docs/notebooks/graph/db\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   [edge,inv_degree])\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/dfs/scratch0/susanctu/newversion/EmptyHeaded/python/database.pyc\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m#Save our schemas to disk (so we can run from_existing)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDisk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;31m#code generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mjava.lang.ExceptionPyRaisable\u001b[0m: java.lang.Exception: ERROR DATABASE FOLDER EXISTS OR IS AN INVALID PATH."
     ]
    }
   ],
   "source": [
    "#add one more relation we need for other tutorials\n",
    "deg = pd.read_csv(eh+\"/test/graph/data/inv_degree.tsv\",\\\n",
    "  sep='\\t',\\\n",
    "  names=[\"0\",\"a_0\"],\\\n",
    "  dtype={\"0\":np.uint32,\"a_0\":np.float32})\n",
    "inv_degree = Relation(\n",
    "    name=\"InvDegree\",\n",
    "    dataframe=deg)\n",
    "db = Database.create(\n",
    "  c,\n",
    "  eh+\"/docs/notebooks/graph/db\",\n",
    "  [edge,inv_degree])\n",
    "db.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That step was slow, it would be nice if we could avoid it if we already have created this database. We can do that with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = Database.from_existing(eh+\"/docs/notebooks/graph/db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! You have created your first EmptyHeaded database. Time to run a query!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='execute'></a>\n",
    "## Execute a Query\n",
    "\n",
    "Now that a database is loaded we are ready to execute a query over the database. We provide details on our query language and accepted datatypes in our [query language tutorial](https://github.com/HazyResearch/EmptyHeaded/tree/master/docs/notebooks). For now we will show how to find all the triangles in this dataset. Execute the datalog rule below to do this! Note: if you are benchmarking EmptyHeaded we print the time to compute each portion of the query in the shell that you launched iPython notebooks from. This separates data loading time from actual query execution! We talk about how to look at the generated code in our [storage engine tutorial](https://github.com/HazyResearch/EmptyHeaded/tree/master/docs/notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.eval(\"Triangle(a,b,c) :- Edge(a,b),Edge(b,c),Edge(a,c).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspect'></a>\n",
    "## Inspect Ouput\n",
    "\n",
    "Now that a query has been executed let's look at the output of the query. We can return it to the front-end as follows. Note this is just a wrapper around the back-end class. We can inspect the following fields of the relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is annotated: False\n",
      "number of triangles: 9672060\n",
      "number of columns:3\n"
     ]
    }
   ],
   "source": [
    "tri = db.get(\"Triangle\")\n",
    "print \"is annotated: \" + str(tri.annotated)\n",
    "print \"number of triangles: \" +str(tri.num_rows)\n",
    "print \"number of columns:\" + str(tri.num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can return a dataframe of the relation with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0     1     2\n",
      "0           0     1    48\n",
      "1           0     1    53\n",
      "2           0     1    54\n",
      "3           0     1    73\n",
      "4           0     1    88\n",
      "5           0     1    92\n",
      "6           0     1   119\n",
      "7           0     1   126\n",
      "8           0     1   133\n",
      "9           0     1   194\n",
      "10          0     1   236\n",
      "11          0     1   280\n",
      "12          0     1   299\n",
      "13          0     1   315\n",
      "14          0     1   322\n",
      "15          0     1   346\n",
      "16          0     2    20\n",
      "17          0     2   115\n",
      "18          0     2   116\n",
      "19          0     2   149\n",
      "20          0     2   226\n",
      "21          0     2   312\n",
      "22          0     2   326\n",
      "23          0     2   333\n",
      "24          0     2   343\n",
      "25          0     3     9\n",
      "26          0     3    25\n",
      "27          0     3    26\n",
      "28          0     3    67\n",
      "29          0     3    72\n",
      "...       ...   ...   ...\n",
      "9672030  4038  4004  3980\n",
      "9672031  4038  4004  4013\n",
      "9672032  4038  4004  4020\n",
      "9672033  4038  4004  4023\n",
      "9672034  4038  4004  4031\n",
      "9672035  4038  4013  3980\n",
      "9672036  4038  4013  3989\n",
      "9672037  4038  4013  4004\n",
      "9672038  4038  4013  4023\n",
      "9672039  4038  4013  4031\n",
      "9672040  4038  4014  3980\n",
      "9672041  4038  4014  4023\n",
      "9672042  4038  4020  3980\n",
      "9672043  4038  4020  4004\n",
      "9672044  4038  4020  4027\n",
      "9672045  4038  4020  4031\n",
      "9672046  4038  4023  3980\n",
      "9672047  4038  4023  4004\n",
      "9672048  4038  4023  4013\n",
      "9672049  4038  4023  4014\n",
      "9672050  4038  4023  4031\n",
      "9672051  4038  4027  3980\n",
      "9672052  4038  4027  4020\n",
      "9672053  4038  4027  4031\n",
      "9672054  4038  4031  3980\n",
      "9672055  4038  4031  4004\n",
      "9672056  4038  4031  4013\n",
      "9672057  4038  4031  4020\n",
      "9672058  4038  4031  4023\n",
      "9672059  4038  4031  4027\n",
      "\n",
      "[9672060 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print tri.getDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spinning Down\n",
    "\n",
    "We stop the JVM with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
